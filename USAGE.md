# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… ØªÙˆÙ„ÛŒØ¯ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù†Ú©ÛŒ

## ğŸš€ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹

### 1. Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
```bash
# Ú©Ù„ÙˆÙ† Ù¾Ø±ÙˆÚ˜Ù‡
git clone <repository-url>
cd banking_synthetic_data

# Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
pip install -r requirements.txt

# Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
python -c "from src.utils.config import setup_directories; setup_directories()"
```

### 2. Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ (Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡)
```bash
# ØªÙˆÙ„ÛŒØ¯ 1000 Ú©Ø§Ø±Ø¨Ø± Ù†Ù…ÙˆÙ†Ù‡
python main.py --sample

# Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
python main.py --analysis
```

### 3. Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„
```bash
# ØªÙˆÙ„ÛŒØ¯ Ú©Ø§Ù…Ù„ 1 Ù…ÛŒÙ„ÛŒÙˆÙ† Ú©Ø§Ø±Ø¨Ø± + ØªØ­Ù„ÛŒÙ„
python main.py --all
```

## ğŸ“Š Ù…Ø±Ø§Ø­Ù„ Ù…Ø®ØªÙ„Ù Ø§Ø¬Ø±Ø§

### Ù…Ø±Ø­Ù„Ù‡ 1: ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡
```bash
python main.py --sample
```

**Ø®Ø±ÙˆØ¬ÛŒ:**
- `database/banking_sample.db` - Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù†Ù…ÙˆÙ†Ù‡
- `output/reports/sample_generation_report.txt` - Ú¯Ø²Ø§Ø±Ø´ ØªÙˆÙ„ÛŒØ¯
- `output/reports/sample_noise_analysis.txt` - ØªØ­Ù„ÛŒÙ„ Ù†ÙˆÛŒØ²

**Ø¢Ù…Ø§Ø± Ù†Ù…ÙˆÙ†Ù‡:**
- 1,000 Ú©Ø§Ø±Ø¨Ø±
- ~80,000 ØªØ±Ø§Ú©Ù†Ø´
- ~3% Ù†ÙˆÛŒØ²
- Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: 10-15 Ø«Ø§Ù†ÛŒÙ‡

### Ù…Ø±Ø­Ù„Ù‡ 2: ØªÙˆÙ„ÛŒØ¯ dataset Ú©Ø§Ù…Ù„
```bash
python main.py --full
```

**Ø®Ø±ÙˆØ¬ÛŒ:**
- `database/banking_data.db` - Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©Ø§Ù…Ù„ (~15 GB)
- Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ ØªÙØµÛŒÙ„ÛŒ
- Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„ Ù†ÙˆÛŒØ²Ù‡Ø§

**Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„:**
- 1,000,000 Ú©Ø§Ø±Ø¨Ø±
- ~80,000,000 ØªØ±Ø§Ú©Ù†Ø´
- ~3.8% Ù†ÙˆÛŒØ²
- Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: 2-3 Ø³Ø§Ø¹Øª

### Ù…Ø±Ø­Ù„Ù‡ 3: ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
```bash
python main.py --analysis
```

**Ø´Ø§Ù…Ù„:**
1. **Feature Engineering** - Ø§Ø³ØªØ®Ø±Ø§Ø¬ 25+ ÙˆÛŒÚ˜Ú¯ÛŒ
2. **Clustering** - Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
3. **Anomaly Detection** - ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ Ø¨Ø§ SHAP
4. **Similarity Search** - Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ´Ø§Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†

**Ø®Ø±ÙˆØ¬ÛŒ:**
- `output/analysis_summary.json` - Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
- `output/plots/` - Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ
- Ø¬Ø¯Ø§ÙˆÙ„ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³

## ğŸ““ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Jupyter Notebooks

### 1. Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡
```bash
jupyter notebook notebooks/01_data_generation.ipynb
```

### 2. Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Feature Engineering
```bash
jupyter notebook notebooks/02_feature_engineering.ipynb
```

### 3. Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Clustering
```bash
jupyter notebook notebooks/03_clustering_analysis.ipynb
```

### 4. Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Anomaly Detection
```bash
jupyter notebook notebooks/04_anomaly_detection.ipynb
```

## ğŸ”§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ

### ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ
```python
from src.data_generation.generators import BankingDataGenerator
from src.database.sqlite_manager import SQLiteManager

# Ø§ÛŒØ¬Ø§Ø¯ Ù…ÙˆÙ„Ø¯ Ø¯Ø§Ø¯Ù‡
db_manager = SQLiteManager()
generator = BankingDataGenerator(db_manager)

# ØªÙˆÙ„ÛŒØ¯ 5000 Ú©Ø§Ø±Ø¨Ø±
stats = generator.generate_sample_data(num_users=5000)
print(f"ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {stats['total_transactions_generated']:,} ØªØ±Ø§Ú©Ù†Ø´")

generator.close()
```

### Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ
```python
from src.feature_engineering.extractors import BankingFeatureExtractor

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø®Ø§Øµ
extractor = BankingFeatureExtractor()
user_ids = [1, 2, 3, 4, 5]

features_df = extractor.extract_features_batch(user_ids)
print(f"ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡: {len(features_df.columns)}")
```

### Ø§Ø¬Ø±Ø§ÛŒ Clustering
```python
from src.analysis.clustering import BankingCustomerClustering

# ØªØ­Ù„ÛŒÙ„ clustering
clustering = BankingCustomerClustering()
results = clustering.run_complete_clustering_analysis(sample_size=5000)

print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´: {results['best_method']}")
print(f"ØªØ¹Ø¯Ø§Ø¯ cluster Ù‡Ø§: {len(results['cluster_profiles'])}")
```

### ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ
```python
from src.analysis.anomaly_detection import BankingAnomalyDetector

# ØªØ´Ø®ÛŒØµ Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒ
detector = BankingAnomalyDetector()
results = detector.run_complete_anomaly_analysis(sample_size=5000)

print(f"Ù†Ø§Ù‡Ù†Ø¬Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø´Ùâ€ŒØ´Ø¯Ù‡: {results['total_anomalies_detected']}")
```

### Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ´Ø§Ø¨Ù‡
```python
from src.analysis.similarity_search import BankingSimilaritySearch

# Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ´Ø§Ø¨Ù‡
similarity = BankingSimilaritySearch()
results = similarity.run_complete_similarity_analysis()

print(f"Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØªØ³Øª Ø¬Ø¯ÛŒØ¯: {results['new_test_users']}")
```

## ğŸ“ˆ ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§

### Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
```python
from src.utils.visualization import BankingVisualizationUtils

visualizer = BankingVisualizationUtils()

# Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¬Ø§Ù…Ø¹
features_df = # ... Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ
transactions_df = # ... Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø§Ú©Ù†Ø´

dashboard = visualizer.create_comprehensive_dashboard(
    features_df, 
    transactions_df
)
```

### Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ®ØµØµÛŒ
```python
# Ù†Ù…ÙˆØ¯Ø§Ø± ØªÙˆØ²ÛŒØ¹ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
fig1 = visualizer.plot_feature_distributions(features_df)

# Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
fig2 = visualizer.plot_correlation_matrix(features_df)

# Ù†ØªØ§ÛŒØ¬ clustering
fig3 = visualizer.plot_clustering_results(features_df, cluster_labels, "kmeans")

# Ù†ØªØ§ÛŒØ¬ anomaly detection
fig4 = visualizer.plot_anomaly_analysis(features_df, anomaly_scores, is_anomaly, "isolation_forest")
```

## ğŸ›ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡

### ØªØºÛŒÛŒØ± Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡
```python
# Ø¯Ø± src/utils/config.py
DATA_GENERATION_CONFIG = {
    'default_users_count': 1000000,  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    'chunk_size': 10000,             # Ø§Ù†Ø¯Ø§Ø²Ù‡ chunk
    'min_transactions_per_user': 20, # Ø­Ø¯Ø§Ù‚Ù„ ØªØ±Ø§Ú©Ù†Ø´
    'max_transactions_per_user': 2000, # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ±Ø§Ú©Ù†Ø´
    
    # Ù†Ø±Ø® Ù†ÙˆÛŒØ²
    'location_noise_rate': 0.02,      # 2%
    'age_amount_noise_rate': 0.005,   # 0.5%
    'time_pattern_noise_rate': 0.01,  # 1%
    'amount_outlier_rate': 0.003      # 0.3%
}
```

### ØªÙ†Ø¸ÛŒÙ… Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ML
```python
# Clustering
clustering_results = clustering.compare_clustering_methods(X)

# Anomaly Detection Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ
iso_results = detector.fit_isolation_forest(X, contamination=0.05)
svm_results = detector.fit_one_class_svm(X, nu=0.05)

# Similarity Search
similarity_results = similarity.find_similar_users(
    target_user_id=12345, 
    n_similar=20
)
```

## ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù†ØªØ§ÛŒØ¬

### Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
```python
# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
db_manager = SQLiteManager()

# Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
users_count = db_manager.execute_query("SELECT COUNT(*) FROM users")
trans_count = db_manager.execute_query("SELECT COUNT(*) FROM transactions")

# Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆÛŒØ²
noise_stats = db_manager.execute_query("""
    SELECT 
        noise_type, 
        COUNT(*) as count,
        COUNT(*) * 100.0 / (SELECT COUNT(*) FROM transactions) as percentage
    FROM transactions 
    WHERE is_noise = 1 
    GROUP BY noise_type
""")

print(noise_stats)
```

### Ø¨Ø±Ø±Ø³ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„
```python
# Ø¨Ø±Ø±Ø³ÛŒ clustering
clustering_results = db_manager.execute_query("SELECT * FROM clustering_results")

# Ø¨Ø±Ø±Ø³ÛŒ anomaly detection
anomaly_results = db_manager.execute_query("SELECT * FROM anomaly_results")

# Ø¨Ø±Ø±Ø³ÛŒ similarity search
similarity_results = db_manager.execute_query("SELECT * FROM similarity_results")
```

## ğŸš¨ Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬

### Ù…Ø´Ú©Ù„ Ø­Ø§ÙØ¸Ù‡
```python
# Ú©Ø§Ù‡Ø´ sample size
results = clustering.run_complete_clustering_analysis(sample_size=1000)

# Ú©Ø§Ù‡Ø´ chunk size
generator = BankingDataGenerator(chunk_size=5000)
```

### Ù…Ø´Ú©Ù„ Ø³Ø±Ø¹Øª
```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©ÙˆÚ†Ú©ØªØ±
db_manager = SQLiteManager("database/banking_sample.db")

# Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
important_features = ['total_amount', 'total_transactions', 'age']
```

### Ù…Ø´Ú©Ù„ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
```bash
# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø®ØªÛŒØ§Ø±ÛŒ
pip install umap-learn hdbscan shap

# Ø¯Ø± ØµÙˆØ±Øª Ù…Ø´Ú©Ù„
pip install --upgrade scikit-learn pandas numpy
```

## ğŸ“ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ

```
output/
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ comprehensive_dashboard.png
â”‚   â”œâ”€â”€ clustering_kmeans.png
â”‚   â”œâ”€â”€ anomaly_isolation_forest.png
â”‚   â””â”€â”€ similarity_analysis.png
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ sample_generation_report.txt
â”‚   â”œâ”€â”€ full_generation_report.txt
â”‚   â”œâ”€â”€ sample_noise_analysis.txt
â”‚   â””â”€â”€ full_noise_analysis.txt
â””â”€â”€ analysis_summary.json
```

## ğŸ¯ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ

### Ø³Ù†Ø§Ø±ÛŒÙˆ 1: ØªØ­Ù„ÛŒÙ„ Ø³Ø±ÛŒØ¹ Ø¯Ø§Ø¯Ù‡ Ú©ÙˆÚ†Ú©
```bash
# ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆÙ†Ù‡ Ú©ÙˆÚ†Ú©
python main.py --sample

# ØªØ­Ù„ÛŒÙ„ Ø³Ø±ÛŒØ¹
python main.py --analysis
```

### Ø³Ù†Ø§Ø±ÛŒÙˆ 2: Ù¾Ø±ÙˆÚ˜Ù‡ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
```bash
# Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ (2-3 Ø³Ø§Ø¹Øª)
python main.py --all
```

### Ø³Ù†Ø§Ø±ÛŒÙˆ 3: ØªÙˆØ³Ø¹Ù‡ Ùˆ ØªØ³Øª
```bash
# ÙÙ‚Ø· ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡
python main.py --sample

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² notebook Ø¨Ø±Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´
jupyter notebook notebooks/
```

---

**ğŸ’¡ Ù†Ú©ØªÙ‡:** Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±ØŒ Ø§Ø² `--sample` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡ØŒ Ø§Ø² `--all` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯. 