#!/usr/bin/env python3
"""
ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ pipeline Ø¨Ø±Ø§ÛŒ 1 Ù…ÛŒÙ„ÛŒÙˆÙ† Ø¯Ø§Ø¯Ù‡
"""

import sys
import os
import time
import psutil
from datetime import datetime

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± src
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.database.sqlite_manager import SQLiteManager
from src.data_generation.generators import BankingDataGenerator
from src.feature_engineering.extractors import BankingFeatureExtractor

def monitor_resources():
    """Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ù…Ù†Ø§Ø¨Ø¹ Ø³ÛŒØ³ØªÙ…"""
    process = psutil.Process(os.getpid())
    memory_mb = process.memory_info().rss / 1024 / 1024
    cpu_percent = process.cpu_percent()
    
    return {
        'memory_mb': memory_mb,
        'cpu_percent': cpu_percent,
        'available_memory_gb': psutil.virtual_memory().available / (1024**3)
    }

def test_1m_data_generation():
    """ØªØ³Øª ØªÙˆÙ„ÛŒØ¯ 1 Ù…ÛŒÙ„ÛŒÙˆÙ† Ø¯Ø§Ø¯Ù‡"""
    print("ğŸ§ª ØªØ³Øª ØªÙˆÙ„ÛŒØ¯ 1 Ù…ÛŒÙ„ÛŒÙˆÙ† Ø¯Ø§Ø¯Ù‡...")
    
    start_time = time.time()
    initial_resources = monitor_resources()
    
    try:
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ø®ØµÙˆØµ ØªØ³Øª
        db_manager = SQLiteManager("database/test_1m_banking.db")
        generator = BankingDataGenerator(db_manager)
        
        print(f"ğŸ“Š Ø´Ø±ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø± {datetime.now()}")
        print(f"ğŸ’¾ Ø­Ø§ÙØ¸Ù‡ Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ: {initial_resources['memory_mb']:.1f} MB")
        print(f"ğŸ’» Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯: {initial_resources['available_memory_gb']:.1f} GB")
        
        # ØªÙˆÙ„ÛŒØ¯ dataset Ú©Ø§Ù…Ù„
        stats = generator.generate_complete_dataset()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø³ Ø§Ø² ØªÙˆÙ„ÛŒØ¯
        final_resources = monitor_resources()
        generation_time = time.time() - start_time
        
        print("\n" + "="*50)
        print("âœ… Ù†ØªØ§ÛŒØ¬ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡:")
        print("="*50)
        print(f"ğŸ‘¥ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡: {stats['total_users_generated']:,}")
        print(f"ğŸ’³ ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡: {stats['total_transactions_generated']:,}")
        print(f"â±ï¸  Ø²Ù…Ø§Ù† ØªÙˆÙ„ÛŒØ¯: {generation_time:.1f} Ø«Ø§Ù†ÛŒÙ‡ ({generation_time/60:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡)")
        print(f"ğŸ“ˆ Ø³Ø±Ø¹Øª: {stats['total_transactions_generated']/generation_time:.0f} ØªØ±Ø§Ú©Ù†Ø´/Ø«Ø§Ù†ÛŒÙ‡")
        print(f"ğŸ’¾ Ø­Ø§ÙØ¸Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {final_resources['memory_mb'] - initial_resources['memory_mb']:.1f} MB")
        print(f"ğŸ’½ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {stats['database_stats']['database_size_mb']:.1f} MB")
        
        generator.close()
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡: {e}")
        return False

def test_feature_extraction_performance():
    """ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ"""
    print("\nğŸ§ª ØªØ³Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ 1M Ú©Ø§Ø±Ø¨Ø±...")
    
    try:
        db_manager = SQLiteManager("database/test_1m_banking.db")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        users_count = db_manager.execute_query("SELECT COUNT(*) as count FROM users").iloc[0]['count']
        print(f"ğŸ“Š Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…ÙˆØ¬ÙˆØ¯: {users_count:,}")
        
        if users_count == 0:
            print("âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø¨ØªØ¯Ø§ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯.")
            return False
        
        feature_extractor = BankingFeatureExtractor(db_manager)
        
        # ØªØ³Øª Ø¨Ø§ batch Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        batch_sizes = [500, 1000, 2000]
        
        for batch_size in batch_sizes:
            print(f"\nğŸ”¬ ØªØ³Øª Ø¨Ø§ batch_size = {batch_size}")
            
            start_time = time.time()
            start_resources = monitor_resources()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ú©ÙˆÚ†Ú©
            sample_size = min(5000, users_count)
            all_users = db_manager.execute_query("SELECT user_id FROM users ORDER BY RANDOM()")
            sample_user_ids = all_users['user_id'].head(sample_size).tolist()
            
            features_df = feature_extractor.extract_features_batch(sample_user_ids)
            
            extraction_time = time.time() - start_time
            end_resources = monitor_resources()
            
            print(f"  â±ï¸  Ø²Ù…Ø§Ù†: {extraction_time:.1f}s Ø¨Ø±Ø§ÛŒ {sample_size:,} Ú©Ø§Ø±Ø¨Ø±")
            print(f"  ğŸ“ˆ Ø³Ø±Ø¹Øª: {sample_size/extraction_time:.1f} Ú©Ø§Ø±Ø¨Ø±/Ø«Ø§Ù†ÛŒÙ‡")
            print(f"  ğŸ’¾ Ø­Ø§ÙØ¸Ù‡: {end_resources['memory_mb'] - start_resources['memory_mb']:.1f} MB")
            print(f"  ğŸ”§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {len(features_df.columns)} ÙˆÛŒÚ˜Ú¯ÛŒ")
            
            # ØªØ®Ù…ÛŒÙ† Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ 1M
            estimated_time_1m = (users_count / sample_size) * extraction_time
            print(f"  ğŸ• ØªØ®Ù…ÛŒÙ† Ø²Ù…Ø§Ù† 1M: {estimated_time_1m/60:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡")
        
        db_manager.close()
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ: {e}")
        return False

def test_analysis_scalability():
    """ØªØ³Øª Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§"""
    print("\nğŸ§ª ØªØ³Øª Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§...")
    
    try:
        from src.analysis.clustering import BankingCustomerClustering
        from src.analysis.anomaly_detection import BankingAnomalyDetector
        
        db_manager = SQLiteManager("database/test_1m_banking.db")
        
        # ØªØ³Øª clustering Ø¨Ø§ sample Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        sample_sizes = [1000, 5000, 10000, 25000, 50000]
        
        clustering_analyzer = BankingCustomerClustering(db_manager)
        
        print("\nğŸ“Š ØªØ³Øª Clustering:")
        for sample_size in sample_sizes:
            start_time = time.time()
            start_resources = monitor_resources()
            
            try:
                results = clustering_analyzer.run_complete_clustering_analysis(sample_size=sample_size)
                
                analysis_time = time.time() - start_time
                end_resources = monitor_resources()
                
                print(f"  Sample {sample_size:,}: {analysis_time:.1f}s, "
                      f"Memory: {end_resources['memory_mb'] - start_resources['memory_mb']:.1f}MB, "
                      f"Best: {results.get('best_method', 'N/A')}")
                
            except Exception as e:
                print(f"  Sample {sample_size:,}: âŒ {str(e)[:50]}...")
        
        db_manager.close()
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª ØªØ­Ù„ÛŒÙ„: {e}")
        return False

def main():
    """Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„"""
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ³Øª pipeline Ø¨Ø±Ø§ÛŒ 1 Ù…ÛŒÙ„ÛŒÙˆÙ† Ø¯Ø§Ø¯Ù‡")
    print("="*60)
    
    # Ù†Ù…Ø§ÛŒØ´ Ù…Ø´Ø®ØµØ§Øª Ø³ÛŒØ³ØªÙ…
    system_info = monitor_resources()
    print(f"ğŸ’» Ù…Ø´Ø®ØµØ§Øª Ø³ÛŒØ³ØªÙ…:")
    print(f"   Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯: {system_info['available_memory_gb']:.1f} GB")
    print(f"   CPU: {psutil.cpu_count()} cores")
    print()
    
    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§
    tests = [
        ("ØªÙˆÙ„ÛŒØ¯ 1M Ø¯Ø§Ø¯Ù‡", test_1m_data_generation),
        ("Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ", test_feature_extraction_performance),
        ("Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ ØªØ­Ù„ÛŒÙ„", test_analysis_scalability)
    ]
    
    results = {}
    total_start = time.time()
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            success = test_func()
            results[test_name] = "âœ… Ù…ÙˆÙÙ‚" if success else "âŒ Ù†Ø§Ù…ÙˆÙÙ‚"
        except Exception as e:
            results[test_name] = f"âŒ Ø®Ø·Ø§: {str(e)[:30]}..."
    
    total_time = time.time() - total_start
    
    # Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
    print("\n" + "="*60)
    print("ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬ ØªØ³Øªâ€ŒÙ‡Ø§:")
    print("="*60)
    for test_name, result in results.items():
        print(f"{test_name}: {result}")
    print(f"\nâ±ï¸  Ú©Ù„ Ø²Ù…Ø§Ù† ØªØ³Øª: {total_time/60:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡")
    print("="*60)

if __name__ == "__main__":
    main() 