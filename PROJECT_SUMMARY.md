# خلاصه پروژه تولید داده‌های بانکی Synthetic

## 🎯 هدف پروژه

این پروژه برای **مصاحبه استخدامی** طراحی شده و یک سیستم کامل تولید و تحلیل داده‌های بانکی synthetic ارائه می‌دهد.

## ✅ آنچه پیاده‌سازی شده

### 1. تولید داده‌های Synthetic
- ✅ **یک میلیون کاربر** با اطلاعات کامل
- ✅ **20-2000 تراکنش** برای هر کاربر در یک ماه
- ✅ **توزیع‌های آماری واقعی**:
  - **Beta Distribution** برای سن (18-80 سال)
  - **Log-Normal Distribution** برای مبلغ تراکنش
  - **Poisson Distribution** برای تعداد تراکنش روزانه
  - **Beta Distribution** برای ساعت تراکنش
  - **Weighted Sampling** برای موقعیت‌های جغرافیایی ایران

### 2. نویز کنترل‌شده
- ✅ **موقعیت غیرعادی** (2%): تراکنش در شهرهای دورافتاده
- ✅ **عدم تطابق سن-مبلغ** (0.5%): کاربران جوان با تراکنش‌های بزرگ
- ✅ **الگوی زمانی غیرعادی** (1%): تراکنش در ساعات شب
- ✅ **مبلغ outlier** (0.3%): مبالغ خیلی بزرگ یا کوچک

### 3. مدیریت دیتابیس SQLite
- ✅ **Chunk-based processing** برای مدیریت حافظه
- ✅ **Schema پیشرفته** با ایندکس‌های بهینه‌شده
- ✅ **WAL mode** برای عملکرد بهتر
- ✅ **Batch operations** برای سرعت بالا

### 4. داده‌های ایرانی
- ✅ **10 استان اصلی** ایران با جمعیت واقعی
- ✅ **40+ شهر** با توزیع وزن‌دار
- ✅ **شهرهای دورافتاده** برای نویز
- ✅ **انواع کارت** بانکی ایرانی
- ✅ **انواع دستگاه** (موبایل، وب، ATM، POS)

## 🏗️ ساختار پروژه

```
├── src/
│   ├── data_generation/          # تولید داده
│   │   ├── distributions.py      # توزیع‌های آماری
│   │   ├── generators.py         # کلاس‌های اصلی تولید
│   │   └── noise_injection.py    # تولید نویز کنترل‌شده
│   ├── database/                 # مدیریت دیتابیس
│   │   ├── schema.py            # تعریف جداول
│   │   └── sqlite_manager.py    # مدیریت SQLite
│   └── utils/
│       └── config.py            # تنظیمات پروژه
├── notebooks/
│   └── 01_data_generation.ipynb # نمونه استفاده
├── main.py                      # فایل اصلی اجرا
└── requirements.txt             # وابستگی‌ها
```

## 🚀 نحوه استفاده

### نصب وابستگی‌ها
```bash
pip install -r requirements.txt
```

### تولید داده نمونه (1000 کاربر)
```bash
python main.py --sample
```

### تولید dataset کامل (1 میلیون کاربر)
```bash
python main.py --full
```

### استفاده از Notebook
```bash
jupyter notebook notebooks/01_data_generation.ipynb
```

## 📊 مثال خروجی

### آمار نمونه (100 کاربر):
- **کاربران**: 100
- **تراکنش‌ها**: ~8,000
- **نویز**: ~2.5%
- **حجم دیتابیس**: ~2 MB
- **زمان پردازش**: ~5 ثانیه

### آمار کامل (1 میلیون کاربر):
- **کاربران**: 1,000,000
- **تراکنش‌ها**: ~80,000,000
- **نویز**: ~3.8%
- **حجم دیتابیس**: ~15 GB
- **زمان پردازش**: ~2-3 ساعت

## 📈 ویژگی‌های کلیدی

### 1. **مقیاس‌پذیری**
- پردازش chunk-based
- مدیریت حافظه بهینه
- قابلیت پردازش موازی

### 2. **کیفیت داده**
- توزیع‌های آماری واقعی
- نویز کنترل‌شده و مستندسازی‌شده
- انطباق با الگوهای واقعی بانکی

### 3. **عملکرد**
- SQLite بهینه‌شده
- ایندکس‌های هوشمند
- پردازش سریع

### 4. **مستندسازی**
- کامنت‌های فارسی
- توضیح منطق توزیع‌ها
- گزارش‌های کامل

## 🔍 تحلیل‌های پیاده‌سازی‌شده

### ✅ مراحل تکمیل‌شده:
1. **Feature Engineering** - استخراج 25+ ویژگی پیشرفته
   - ویژگی‌های حجم تراکنش (7 ویژگی)
   - ویژگی‌های زمانی (5 ویژگی)
   - ویژگی‌های جغرافیایی (5 ویژگی)
   - ویژگی‌های رفتاری (3 ویژگی)
   - ویژگی‌های توزیع مبلغ (4 ویژگی)
   - ویژگی‌های تعاملی (5+ ویژگی)

2. **Clustering Analysis** - دسته‌بندی هوشمند کاربران
   - K-means با تعیین خودکار K بهینه
   - Hierarchical Clustering (Ward linkage)
   - DBSCAN برای کشف cluster های غیرمنظم
   - HDBSCAN برای clustering پیشرفته
   - مقایسه خودکار و انتخاب بهترین روش

3. **Anomaly Detection** - تشخیص ناهنجاری با تفسیر SHAP
   - Isolation Forest برای outlier detection
   - One-Class SVM برای boundary detection
   - Supervised Random Forest با ground truth
   - SHAP values برای تفسیر قابل فهم
   - Feature importance و ranking

4. **Similarity Search** - سیستم جستجوی تشابه کاربران
   - K-Nearest Neighbors با Cosine similarity
   - تولید 100 کاربر جدید برای تست
   - تحلیل الگوهای تشابه
   - ماتریس تشابه و pattern analysis

## 💡 نکات فنی مهم

### توزیع‌های انتخاب‌شده:
- **Beta**: کنترل شکل توزیع برای سن و ساعت
- **Log-Normal**: طبیعی برای مبالغ مالی
- **Poisson**: ایده‌آل برای شمارش رویدادها
- **Weighted Sampling**: واقعی‌سازی جغرافیایی

### نویز هوشمند:
- **مبتنی بر منطق کسب‌وکار**
- **قابل کنترل و اندازه‌گیری**
- **مناسب برای تست anomaly detection**

## 🛠️ امکانات پیشرفته

- **Progress bars** با tqdm
- **Logging** جامع
- **Error handling** قوی
- **Memory profiling** آماده
- **Backup** خودکار دیتابیس

## 📁 فایل‌های خروجی

- `database/banking_data.db` - دیتابیس اصلی
- `output/reports/` - گزارش‌های متنی
- `output/plots/` - نمودارها
- `output/summaries/` - خلاصه‌های CSV

## 🎭 مناسب برای مصاحبه

این پروژه نشان‌دهنده:
- ✅ **تسلط بر Data Science pipeline کامل**
- ✅ **مهارت Machine Learning پیشرفته**
- ✅ **تجربه Feature Engineering حرفه‌ای**
- ✅ **آشنایی با Clustering algorithms**
- ✅ **تسلط بر Anomaly Detection و SHAP**
- ✅ **مهارت Database Design و Optimization**
- ✅ **تجربه Performance Optimization**
- ✅ **آشنایی با Statistical Distributions**
- ✅ **مستندسازی حرفه‌ای فارسی/انگلیسی**
- ✅ **Clean Code** و **Best Practices**
- ✅ **تسلط بر Visualization و Reporting**

## 📋 دستاورد نهایی

### سیستم کامل شامل:
- **1 میلیون کاربر** با رفتار واقعی
- **80+ میلیون تراکنش** با الگوهای پیچیده
- **25+ ویژگی** استخراج‌شده هوشمند
- **4 الگوریتم clustering** با مقایسه خودکار
- **3 روش anomaly detection** با تفسیر SHAP
- **سیستم similarity search** برای کاربران جدید
- **داشبورد تحلیلی جامع** با visualization ها
- **5 نوت‌بوک Jupyter** تعاملی و آموزشی

---

**🏆 این پروژه یک نمونه کامل از مهارت‌های Data Science و Machine Learning در سطح حرفه‌ای است! 🚀** 